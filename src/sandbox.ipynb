{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sktime.regression.base import BaseRegressor\n",
    "from sktime.regression.dummy import DummyRegressor\n",
    "from sktime.regression.kernel_based import RocketRegressor\n",
    "from sktime.utils import mlflow_sktime\n",
    "\n",
    "from util.utils import set_all_seeds\n",
    "from data.dataloader import Platoon\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "# Ignore specific warning\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='sktime.base._base_panel')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dummy_regressor\"\n",
    "project_name = \"Version 0.1\"\n",
    "seed = 42\n",
    "num_epochs = 2\n",
    "batch_size = 10\n",
    "window_size = 10\n",
    "verbose = False\n",
    "only_iri = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'D:/sc_ml_and_road_conditions/CrackDetect/data/processed'\n",
    "trainset = Platoon(data_type='train', data_path=data_path, window_size=window_size, only_iri=only_iri)\n",
    "train_loader = DataLoader(trainset, batch_size=None, shuffle=True, num_workers=1)\n",
    "valset = Platoon(data_type='val', data_path=data_path, window_size=window_size, only_iri=only_iri)\n",
    "val_loader = DataLoader(valset, batch_size=None, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different tsai models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os              : Windows-10-10.0.19045-SP0\n",
      "python          : 3.10.11\n",
      "tsai            : 0.3.9\n",
      "fastai          : 2.7.14\n",
      "fastcore        : 1.5.29\n",
      "sktime          : 0.27.0\n",
      "sklearn         : 1.4.1.post1\n",
      "torch           : 2.2.1+cpu\n",
      "device          : cpu\n",
      "cpu cores       : 6\n",
      "threads per cpu : 2\n",
      "RAM             : 15.93 GB\n",
      "GPU memory      : [8.0] GB\n"
     ]
    }
   ],
   "source": [
    "from tsai.basics import *\n",
    "import sktime\n",
    "import sklearn\n",
    "my_setup(sktime, sklearn)\n",
    "from tsai.models.MINIROCKET import *\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "def create_batches(data, targets, batch_size):\n",
    "    num_batches = len(data) // batch_size\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        yield np.expand_dims(data[start_idx:end_idx], 1).astype('float32'), targets[start_idx:end_idx].astype('float32')\n",
    "\n",
    "    \"\"\"\n",
    "    NOTE - this is a generator, so the last batch will be smaller, but for certain models \n",
    "    we have to have fixed batch size so we can't just yield the last batch\n",
    "    \"\"\"    \n",
    "    # if len(data) % batch_size != 0:\n",
    "    #     start_idx = num_batches * batch_size\n",
    "    #     yield np.expand_dims(data[start_idx:end_idx], 1).astype('float32'), targets[start_idx:].astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    }
   ],
   "source": [
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "model = MiniRocketRegressor(scoring=rmse_scorer)\n",
    "\n",
    "total_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_iterator = tqdm(train_loader, unit=\"batch\", position=0, leave=False)\n",
    "    train_loss = []\n",
    "    train_iterator.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for data_segment, target_segment in train_iterator:\n",
    "        for data, target in create_batches(data_segment, target_segment, batch_size=batch_size):\n",
    "            model.fit(data, target)\n",
    "            output = model.predict(data)\n",
    "            loss = mean_squared_error(target, output)\n",
    "            train_loss.append(loss)\n",
    "            train_iterator.set_postfix_str(f\"train_loss: {loss:.6f}\")\n",
    "    total_loss.append(np.mean(train_loss))\n",
    "    # iterator.set_postfix_str(f\"train_loss: {total_loss[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 0.344274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "val_iterator = tqdm(val_loader, unit=\"batch\", position=0, leave=False)\n",
    "RMSs = []\n",
    "for data_segment, target_segment in val_iterator:\n",
    "    for data, target in create_batches(data_segment, target_segment, batch_size=batch_size):\n",
    "        y_pred = model.predict(data)\n",
    "        rmse = mean_squared_error(target, y_pred, squared=False)\n",
    "        RMSs.append(rmse)\n",
    "        val_iterator.set_postfix_str(f\"val_loss: {rmse:.6f}\")\n",
    "\n",
    "print(f\"Mean RMSE: {np.mean(RMSs):.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fleetenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
