{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.data.feature_dataloader import Features\n",
    "from src.models.hydramr import HydraMRRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader):\n",
    "    \"\"\"Run prediction for a given model and dataloader.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "        model: model to use for prediction\n",
    "        dataloader: dataloader to use for prediction\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "        all_predictions (torch.Tensor), all_targets (torch.Tensor), test_losses (ndarray): predictions, targets and losses for the test set\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = torch.tensor([])\n",
    "    all_targets = torch.tensor([])\n",
    "    losses = np.array([])\n",
    "    \n",
    "    iterator = tqdm(dataloader, unit=\"batch\", position=0, leave=False)\n",
    "    kpi_means = torch.tensor(dataloader.dataset.kpi_means)\n",
    "    kpi_stds = torch.tensor(dataloader.dataset.kpi_stds)\n",
    "    \n",
    "    for data, targets in iterator:\n",
    "        output = model(data)\n",
    "        \n",
    "        # Convert back from standardized to original scale\n",
    "        output = ((output * kpi_stds) + kpi_means)\n",
    "        targets = ((targets * kpi_stds) + kpi_means)\n",
    "        \n",
    "        loss_fn = nn.MSELoss()\n",
    "        all_predictions = torch.cat((all_predictions, output), dim=0)\n",
    "        all_targets = torch.cat((all_targets, targets), dim=0)\n",
    "        \n",
    "        loss = loss_fn(output, targets).item()\n",
    "        losses = np.append(losses, loss)\n",
    "        \n",
    "        iterator.set_description(f'Overall RMSE (loss): {np.sqrt(losses.mean()):.2f} Batch RMSE (loss): {np.sqrt(loss):.2f}')\n",
    "    \n",
    "    return all_predictions, all_targets, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: \n",
      "                     Data Path:             ../data/processed/features.hdf5 \n",
      "                     Data Type:             train \n",
      "                     Data length:           6551 \n",
      "                     Features selected:                      \n",
      "                         - Names:           ['HydraMV_8_64'] \n",
      "                         - KPI Window Size: 1 \n",
      "                     \n",
      "Arguments: \n",
      "                     Data Path:             ../data/processed/features.hdf5 \n",
      "                     Data Type:             val \n",
      "                     Data length:           1637 \n",
      "                     Features selected:                      \n",
      "                         - Names:           ['HydraMV_8_64'] \n",
      "                         - KPI Window Size: 1 \n",
      "                     \n",
      "Arguments: \n",
      "                     Data Path:             ../data/processed/features.hdf5 \n",
      "                     Data Type:             test \n",
      "                     Data length:           1446 \n",
      "                     Features selected:                      \n",
      "                         - Names:           ['HydraMV_8_64'] \n",
      "                         - KPI Window Size: 1 \n",
      "                     \n"
     ]
    }
   ],
   "source": [
    "fold = 3\n",
    "feature_extractors = ['HydraMV_8_64']\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "feature_path = Path(f\"../data/processed/features.hdf5\")\n",
    "\n",
    "datasets = {\n",
    "    \"train\": Features(feature_path, data_type=\"train\", feature_extractors=feature_extractors, fold=fold),\n",
    "    \"val\": Features(feature_path, data_type=\"val\", feature_extractors=feature_extractors, fold=fold),\n",
    "    \"test\": Features(feature_path, data_type=\"test\", feature_extractors=feature_extractors, fold=fold)\n",
    "\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(datasets[\"train\"], batch_size=batch_size, shuffle=False, num_workers=0),\n",
    "    \"val\": DataLoader(datasets[\"val\"], batch_size=batch_size, shuffle=False, num_workers=0),\n",
    "    \"test\": DataLoader(datasets[\"test\"], batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "input_shape, target_shape = datasets[\"train\"].get_data_shape()\n",
    "\n",
    "model_path = Path(\"../models/best_HydraMRRegressor_3.pt\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "hidden_dim = 256\n",
    "model_depth = 1\n",
    "batch_norm = True\n",
    "\n",
    "model = HydraMRRegressor(in_features=input_shape[0], out_features=target_shape[0], hidden_dim=hidden_dim, model_depth=model_depth, batch_norm=batch_norm)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val RMSE: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "all_predictions = torch.tensor([])\n",
    "all_targets = torch.tensor([])\n",
    "\n",
    "for dataset_type in [\"train\", \"val\", \"test\"]:\n",
    "    predictions, targets, losses = predict(model, dataloaders[dataset_type])\n",
    "    all_predictions = torch.cat((all_predictions, predictions), dim=0)\n",
    "    all_targets = torch.cat((all_targets, targets), dim=0)\n",
    "    print(f\"{dataset_type} RMSE: {np.mean(np.sqrt(losses)):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7721508128171716, 2.756725926569798, 0.04157282451083849, 3.799090905791356]\n"
     ]
    }
   ],
   "source": [
    "data_seg_sec_list = datasets[\"train\"].indices + datasets[\"val\"].indices + datasets[\"test\"].indices\n",
    "data_seg_sec_list\n",
    "\n",
    "# Initialize the nested dictionary\n",
    "road_predictions = {}\n",
    "\n",
    "# Iterate through data_seg_sec_list and all_predictions to populate the dictionary\n",
    "for idx, (outer_key, inner_key) in enumerate(data_seg_sec_list):\n",
    "    outer_key, inner_key = int(outer_key), int(inner_key)\n",
    "    if outer_key not in road_predictions:\n",
    "        road_predictions[outer_key] = {}\n",
    "    road_predictions[outer_key][inner_key] = all_predictions[idx].tolist()\n",
    "\n",
    "print(road_predictions[0][11])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fleetenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
