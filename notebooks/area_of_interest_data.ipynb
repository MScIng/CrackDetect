{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From time predictions to location predictions\n",
    "\n",
    "We will try predicting the road condition in 1 meter intervals.\n",
    "\n",
    "The issue before have been we have only used intervals, which just had the length of whatever far one could travel in 1 second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import cm\n",
    "import h5py\n",
    "from scipy.interpolate import CubicSpline\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {\n",
    "        'acc_long':     {'bstar': 198,      'rstar': 1,     'b': 198,   'r': 0.05   },\n",
    "        'acc_trans':    {'bstar': 32768,    'rstar': 1,     'b': 32768, 'r': 0.04   },\n",
    "        'acc_yaw':      {'bstar': 2047,     'rstar': 1,     'b': 2047,  'r': 0.1    },\n",
    "        'brk_trq_elec': {'bstar': 4096,     'rstar': -1,    'b': 4098,  'r': -1     },\n",
    "        'whl_trq_est':  {'bstar': 12800,    'rstar': 0.5,   'b': 12700, 'r': 1      },\n",
    "        'trac_cons':    {'bstar': 80,       'rstar': 1,     'b': 79,    'r': 1      },\n",
    "        'trip_cons':    {'bstar': 0,        'rstar': 0.1,   'b': 0,     'r': 1      }\n",
    "    }\n",
    "\n",
    "def convertdata(data, parameter):\n",
    "    bstar = parameter['bstar']\n",
    "    rstar = parameter['rstar']\n",
    "    b = parameter['b']\n",
    "    r = parameter['r']\n",
    "    # We only convert data in the second column at idx 1 (wrt. 0-indexing), as the first column is time\n",
    "    col0 = data[:,0]\n",
    "    col1 = ((data[:,1]-bstar*rstar)-b)*r\n",
    "    data = np.column_stack((col0, col1))\n",
    "    return data\n",
    "\n",
    "\n",
    "def unpack_hdf5(hdf5_file, convert: bool = False):\n",
    "    with h5py.File(hdf5_file, 'r') as f:\n",
    "        print(f)\n",
    "        data = unpack_hdf5_(f, convert)\n",
    "    return data\n",
    "\n",
    "\n",
    "def unpack_hdf5_(group, convert: bool = False):\n",
    "    data = {}\n",
    "    for key in group.keys():\n",
    "        if isinstance(group[key], h5py.Group):\n",
    "            data[key] = unpack_hdf5_(group[key])\n",
    "        else:\n",
    "            if convert and key in parameter_dict:\n",
    "                data[key] = convertdata(group[key][()], parameter_dict[key])\n",
    "            else:\n",
    "                d = group[key][()]\n",
    "                if isinstance(d, bytes):\n",
    "                    data[key] = d.decode('utf-8')\n",
    "                else:\n",
    "                    data[key] = group[key][()]\n",
    "    return data\n",
    "\n",
    "\n",
    "def find_best_start_and_end_indeces_by_lonlat(trip: np.ndarray, section: np.ndarray):\n",
    "    # Find the start and end indeces of the section data that are closest to the trip data\n",
    "    lon_a, lat_a = trip[:,0], trip[:,1]\n",
    "    lon_b, lat_b = section[:,0], section[:,1]\n",
    "    \n",
    "    start_index = np.argmin(np.linalg.norm(np.column_stack((lon_a, lat_a)) - np.array([lon_b[0], lat_b[0]]), axis=1))\n",
    "    end_index = np.argmin(np.linalg.norm(np.column_stack((lon_a, lat_a)) - np.array([lon_b[-1], lat_b[-1]]), axis=1))\n",
    "\n",
    "    return start_index, end_index\n",
    "\n",
    "\n",
    "def time_to_drive_X_meters(speed_kmh, distance_m=10):\n",
    "    # Convert speed from km/h to m/s\n",
    "    speed_ms = speed_kmh * (1000 / 3600)\n",
    "\n",
    "    # Calculate time in seconds\n",
    "    time_seconds = distance_m / speed_ms\n",
    "    \n",
    "    return time_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: We are only doing it for the right side (hh) here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 file \"platoon_CPH1_HH.hdf5\" (mode r)>\n"
     ]
    }
   ],
   "source": [
    "# Right side\n",
    "autopi_hh = unpack_hdf5('../data/raw/AutoPi_CAN/platoon_CPH1_HH.hdf5')\n",
    "gm_data = autopi_hh['GM']['16006']['pass_1'] # TODO choose a one true route. \n",
    "p79_hh = pd.read_csv('../data/raw/ref_data/cph1_zp_hh.csv', sep=';', encoding='unicode_escape')\n",
    "\n",
    "segments = h5py.File('../data/processed/segments.hdf5', 'r')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1226\n",
      "[[12.53019946, 55.7111808], [12.53018721, 55.71117492], [12.53017498, 55.71116905], [12.53016273, 55.71116317], [12.53015047, 55.7111573]]\n"
     ]
    }
   ],
   "source": [
    "# HH \n",
    "# Extract every 10th item starting from idx[0] to idx[1]+1, to get one location for each meter\n",
    "lon_zp_hh = p79_hh['Lon']\n",
    "lat_zp_hh = p79_hh['Lat']\n",
    "idx_hh = find_best_start_and_end_indeces_by_lonlat(p79_hh[['Lat', 'Lon']].to_numpy(), gm_data['gps'][:,1:]) # TODO is this really the best place to start?? \n",
    "loc_hh_lon = lon_zp_hh[idx_hh[0]:idx_hh[1]+1:10]\n",
    "loc_hh_lat = lat_zp_hh[idx_hh[0]:idx_hh[1]+1:10]\n",
    "\n",
    "# Combine lon and lat into a list of lists\n",
    "loc_hh = [[lon, lat] for lon, lat in zip(loc_hh_lon, loc_hh_lat)]\n",
    "\n",
    "# For demonstration, let's print the first few pairs to verify\n",
    "print(len(loc_hh))\n",
    "print(loc_hh[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16006: ['pass_1', 'pass_2', 'pass_3', 'pass_4', 'pass_5', 'pass_6', 'pass_7', 'pass_8', 'pass_9', 'pass_10', 'pass_11', 'pass_12', 'pass_13', 'pass_14', 'pass_15', 'pass_16', 'pass_17', 'pass_18', 'pass_19']\n",
      "16008: ['pass_1', 'pass_2', 'pass_3', 'pass_4', 'pass_5', 'pass_6', 'pass_7', 'pass_8', 'pass_9', 'pass_10', 'pass_11', 'pass_12', 'pass_13', 'pass_14', 'pass_15', 'pass_16', 'pass_17']\n",
      "16009: ['pass_1', 'pass_2', 'pass_3', 'pass_4', 'pass_5', 'pass_6', 'pass_7', 'pass_8', 'pass_9', 'pass_10', 'pass_11', 'pass_12', 'pass_13', 'pass_14']\n",
      "16010: ['pass_1', 'pass_2', 'pass_3', 'pass_4', 'pass_5', 'pass_6', 'pass_7', 'pass_8', 'pass_9', 'pass_10', 'pass_11', 'pass_12', 'pass_13', 'pass_14']\n",
      "16011: ['pass_1', 'pass_2', 'pass_3', 'pass_4', 'pass_5', 'pass_6', 'pass_7', 'pass_8', 'pass_9', 'pass_10', 'pass_11', 'pass_12', 'pass_13', 'pass_14']\n"
     ]
    }
   ],
   "source": [
    "# Define all_trip_names and pass_lists\n",
    "def natural_key(string):\n",
    "    \"\"\"A key to sort strings that contain numbers naturally.\"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', string)]\n",
    "\n",
    "all_trip_names = ['16006', '16008', '16009', '16010', '16011']\n",
    "# Initialize the dictionary with empty sets for each trip\n",
    "pass_names_for_each_trip = {trip: set() for trip in all_trip_names}\n",
    "\n",
    "# Populate the sets with pass names from the segments\n",
    "for segment in segments.values():\n",
    "    trip_name = segment.attrs[\"trip_name\"]\n",
    "    pass_name = segment.attrs[\"pass_name\"]\n",
    "    pass_names_for_each_trip[trip_name].add(pass_name)\n",
    "\n",
    "# Convert sets to sorted lists using the natural key for sorting\n",
    "for trip in pass_names_for_each_trip:\n",
    "    pass_names_for_each_trip[trip] = sorted(pass_names_for_each_trip[trip], key=natural_key)\n",
    "\n",
    "# Variable assignments for pass lists\n",
    "for trip, passes in pass_names_for_each_trip.items():\n",
    "    globals()[f'pass_list_{trip}'] = passes\n",
    "\n",
    "# Displaying the sorted lists (this would typically be for debugging or checking, not part of production code)\n",
    "pass_lists = {trip: sorted(passes, key=natural_key) for trip, passes in pass_names_for_each_trip.items()}\n",
    "for trip in pass_lists:\n",
    "    print(f\"{trip}: {pass_lists[trip]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16006': {'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_15': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_16': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_17': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_18': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_19': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}, '16008': {'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_15': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_16': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_17': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}, '16009': {'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}, '16010': {'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}, '16011': {'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}}\n",
      "{'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}\n",
      "{'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}\n",
      "[100, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the mapping dictionary\n",
    "mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip = {}\n",
    "\n",
    "for index in range(len(loc_hh)):\n",
    "    trip_data = {}\n",
    "    for trip_name in all_trip_names:\n",
    "        pass_data = {}\n",
    "        for pass_name in pass_lists[trip_name]:\n",
    "            pass_data[pass_name] = {\n",
    "                \"distance_segment_second_1\": [100, 0, 0],\n",
    "                \"distance_segment_second_2\": [200, 0, 0]\n",
    "            }\n",
    "        trip_data[trip_name] = pass_data\n",
    "    mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[index] = trip_data\n",
    "\n",
    "# Accessing the structure for the first index\n",
    "print(mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[0])\n",
    "print(mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[0]['16011'])\n",
    "print(mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[0]['16011']['pass_1'])\n",
    "print(mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[0]['16011']['pass_1']['distance_segment_second_1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1226/1226 [55:11<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Now fill out the dictionary with the correct values\n",
    "for index, real_location in tqdm(enumerate(loc_hh), total=len(loc_hh), desc=\"Processing\"):\n",
    "    for segment in segments.keys():\n",
    "        current_direction = segments[str(segment)].attrs[\"direction\"]\n",
    "        if current_direction == \"vh\": # Check that we are going in the right direction\n",
    "            continue\n",
    "        current_trip_name = segments[str(segment)].attrs[\"trip_name\"]\n",
    "        current_pass_name = segments[str(segment)].attrs[\"pass_name\"]\n",
    "        current_best_trip_1 = mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name][current_pass_name]['distance_segment_second_1']\n",
    "        current_best_trip_2 = mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name][current_pass_name]['distance_segment_second_2']\n",
    "        for second in segments[str(segment)].keys():\n",
    "            current_second = segments[str(segment)][str(second)]\n",
    "            current_second_lat = current_second[\"gm\"][:,15]\n",
    "            current_second_lon = current_second[\"gm\"][:,16]\n",
    "            current_second_locations = [[lon, lat] for lon, lat in zip(current_second_lon, current_second_lat)]\n",
    "            closest_sample_arg = np.argmin(np.linalg.norm(np.column_stack((current_second_lon, current_second_lat)) - np.array([real_location[0], real_location[1]]), axis=1))\n",
    "            best_at_second = current_second_locations[closest_sample_arg]\n",
    "            distance = np.linalg.norm(np.array(best_at_second) - np.array(real_location))\n",
    "            \n",
    "            if distance < current_best_trip_1[0]:\n",
    "                current_best_trip_2 = current_best_trip_1\n",
    "                current_best_trip_1 = [distance, segment, second]\n",
    "                mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name][current_pass_name]['distance_segment_second_1'] = current_best_trip_1\n",
    "                mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name][current_pass_name]['distance_segment_second_2'] = current_best_trip_2\n",
    "                \n",
    "            elif distance < current_best_trip_2[0]:\n",
    "                current_best_trip_2 = [distance, segment, second]\n",
    "                mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name][current_pass_name]['distance_segment_second_2'] = current_best_trip_2\n",
    "            \n",
    "            else: \n",
    "                continue\n",
    "\n",
    "# Save the HH mapping to a CSV file\n",
    "filename = \"mapping_hh_time_to_location.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow(['Index', 'Trip Name', 'Pass Name', 'Distance Segment', 'Value1', 'Value2', 'Value3'])\n",
    "    # Write the data\n",
    "    for index, trips in mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip.items():\n",
    "        for trip_name, passes in trips.items():\n",
    "            for pass_name, segments in passes.items():\n",
    "                for segment_name, values in segments.items():\n",
    "                    # Prepare the row with all needed information\n",
    "                    row = [index, trip_name, pass_name, segment_name] + values\n",
    "                    writer.writerow(row)\n",
    "\n",
    "print(\"CSV file has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the HH mapping to a CSV file\n",
    "filename = \"mapping_hh_time_to_location.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow(['Index', 'Trip Name', 'Pass Name', 'Distance Segment', 'Value1', 'Value2', 'Value3'])\n",
    "    # Write the data\n",
    "    for index, trips in mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip.items():\n",
    "        for trip_name, passes in trips.items():\n",
    "            for pass_name, segments in passes.items():\n",
    "                for segment_name, values in segments.items():\n",
    "                    # Prepare the row with all needed information\n",
    "                    row = [index, trip_name, pass_name, segment_name] + values\n",
    "                    writer.writerow(row)\n",
    "\n",
    "print(\"CSV file has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pass_1': {'distance_segment_second_1': [1.8639465280960233e-05, '38', '2'],\n",
       "  'distance_segment_second_2': [4.218541846208998e-05, '38', '3']},\n",
       " 'pass_2': {'distance_segment_second_1': [100, 0, 0],\n",
       "  'distance_segment_second_2': [200, 0, 0]},\n",
       " 'pass_3': {'distance_segment_second_1': [4.120648748128986e-05, '44', '2'],\n",
       "  'distance_segment_second_2': [6.30595759780742e-05, '44', '3']},\n",
       " 'pass_4': {'distance_segment_second_1': [100, 0, 0],\n",
       "  'distance_segment_second_2': [200, 0, 0]},\n",
       " 'pass_5': {'distance_segment_second_1': [2.508377363051862e-05, '47', '2'],\n",
       "  'distance_segment_second_2': [2.6619532700902304e-05, '47', '1']},\n",
       " 'pass_6': {'distance_segment_second_1': [100, 0, 0],\n",
       "  'distance_segment_second_2': [200, 0, 0]},\n",
       " 'pass_7': {'distance_segment_second_1': [0.00012054763207898648, '49', '0'],\n",
       "  'distance_segment_second_2': [0.0001305584327341958, '49', '1']},\n",
       " 'pass_8': {'distance_segment_second_1': [100, 0, 0],\n",
       "  'distance_segment_second_2': [200, 0, 0]},\n",
       " 'pass_9': {'distance_segment_second_1': [0.0003280855553068379, '51', '0'],\n",
       "  'distance_segment_second_2': [0.00034312469112131723, '51', '1']},\n",
       " 'pass_10': {'distance_segment_second_1': [100, 0, 0],\n",
       "  'distance_segment_second_2': [200, 0, 0]},\n",
       " 'pass_11': {'distance_segment_second_1': [2.778988596828729e-05, '40', '4'],\n",
       "  'distance_segment_second_2': [2.851173766449005e-05, '40', '3']},\n",
       " 'pass_12': {'distance_segment_second_1': [100, 0, 0],\n",
       "  'distance_segment_second_2': [200, 0, 0]},\n",
       " 'pass_13': {'distance_segment_second_1': [5.024776531263841e-06, '42', '2'],\n",
       "  'distance_segment_second_2': [4.1547345684774426e-05, '42', '3']},\n",
       " 'pass_14': {'distance_segment_second_1': [100, 0, 0],\n",
       "  'distance_segment_second_2': [200, 0, 0]}}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[0][\"16009\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot segments for each car.  \n",
    "for segment in segments.keys():\n",
    "    current_trip_name = segments[str(segment)].attrs[\"trip_name\"]\n",
    "    first_second = segments[str(segment)][str(0)]\n",
    "    \n",
    "    for second in segments[str(segment)].keys():\n",
    "        current_second = segments[str(segment)][str(second)]\n",
    "        current_second_lat = current_second[\"gm\"][:,15]\n",
    "        current_second_lon = current_second[\"gm\"][:,16]\n",
    "        current_second_locations = [[lon, lat] for lon, lat in zip(current_second_lon, current_second_lat)]\n",
    "        closest_sample_arg = np.argmin(np.linalg.norm(np.column_stack((current_second_lon, current_second_lat)) - np.array([real_location[0], real_location[1]]), axis=1))\n",
    "        best_at_second = current_second_locations[closest_sample_arg]\n",
    "        distance = np.linalg.norm(np.array(best_at_second) - np.array(real_location))\n",
    "        \n",
    "        if distance < current_best_trip_1[0]:\n",
    "            current_best_trip_2 = current_best_trip_1\n",
    "            current_best_trip_1 = [distance, segment, second]\n",
    "            mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name]['distance_segment_second_1'] = current_best_trip_1\n",
    "            mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name]['distance_segment_second_2'] = current_best_trip_2\n",
    "            \n",
    "        elif distance < current_best_trip_2[0]:\n",
    "            current_best_trip_2 = [distance, segment, second]\n",
    "            mapping_hh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name]['distance_segment_second_2'] = current_best_trip_2\n",
    "        \n",
    "        else: \n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_filename = 'trip_data_hh.hdf5'\n",
    "\n",
    "# Create a new HDF5 file\n",
    "with h5py.File(hdf5_filename, 'w') as hdf:\n",
    "    for trip_id, segments in ex_mapping_to_the_two_best_seconds_for_each_trip.items():\n",
    "        group = hdf.create_group(str(trip_id))\n",
    "        for segment_id, segment_data in segments.items():\n",
    "            # Convert each segment's data into a numpy array for easier handling\n",
    "            ds_data = np.array([segment_data['distance_segment_second_1'],\n",
    "                                segment_data['distance_segment_second_2']])\n",
    "            # Each dataset is named after the segment ID\n",
    "            group.create_dataset(segment_id, data=ds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: We are only doing it for the left side (vh) here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 file \"platoon_CPH1_VH.hdf5\" (mode r)>\n"
     ]
    }
   ],
   "source": [
    "# Left side\n",
    "autopi_vh = unpack_hdf5('../data/raw/AutoPi_CAN/platoon_CPH1_VH.hdf5')\n",
    "gm_data = autopi_vh['GM']['16006']['pass_2'] # pass two is a VH route\n",
    "p79_vh = pd.read_csv('../data/raw/ref_data/cph1_zp_vh.csv', sep=';', encoding='unicode_escape')\n",
    "\n",
    "segments = h5py.File('../data/processed/segments.hdf5', 'r')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940\n",
      "[[12.52125164, 55.70485965], [12.52125497, 55.70486815], [12.52125829, 55.70487666], [12.52126164, 55.70488519], [12.52126493, 55.70489373]]\n"
     ]
    }
   ],
   "source": [
    "# VH \n",
    "# Extract every 10th item starting from idx[0] to idx[1]+1, to get one location for each meter\n",
    "lon_zp_vh = p79_vh['Lon']\n",
    "lat_zp_vh = p79_vh['Lat']\n",
    "idx_vh = find_best_start_and_end_indeces_by_lonlat(p79_vh[['Lat', 'Lon']].to_numpy(), gm_data['gps'][:,1:]) # TODO is this really the best place to start?? \n",
    "loc_vh_lon = lon_zp_vh[idx_vh[0]:idx_vh[1]+1:10]\n",
    "loc_vh_lat = lat_zp_vh[idx_vh[0]:idx_vh[1]+1:10]\n",
    "\n",
    "# Combine lon and lat into a list of lists\n",
    "loc_vh = [[lon, lat] for lon, lat in zip(loc_vh_lon, loc_vh_lat)]\n",
    "\n",
    "# For demonstration, let's print the first few pairs to verify\n",
    "print(len(loc_vh))\n",
    "print(loc_vh[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16006: ['pass_1', 'pass_2', 'pass_3', 'pass_4', 'pass_5', 'pass_6', 'pass_7', 'pass_8', 'pass_9', 'pass_10', 'pass_11', 'pass_12', 'pass_13', 'pass_14', 'pass_15', 'pass_16', 'pass_17', 'pass_18', 'pass_19']\n",
      "16008: ['pass_1', 'pass_2', 'pass_3', 'pass_4', 'pass_5', 'pass_6', 'pass_7', 'pass_8', 'pass_9', 'pass_10', 'pass_11', 'pass_12', 'pass_13', 'pass_14', 'pass_15', 'pass_16', 'pass_17']\n",
      "16009: ['pass_1', 'pass_2', 'pass_3', 'pass_4', 'pass_5', 'pass_6', 'pass_7', 'pass_8', 'pass_9', 'pass_10', 'pass_11', 'pass_12', 'pass_13', 'pass_14']\n",
      "16010: ['pass_1', 'pass_2', 'pass_3', 'pass_4', 'pass_5', 'pass_6', 'pass_7', 'pass_8', 'pass_9', 'pass_10', 'pass_11', 'pass_12', 'pass_13', 'pass_14']\n",
      "16011: ['pass_1', 'pass_2', 'pass_3', 'pass_4', 'pass_5', 'pass_6', 'pass_7', 'pass_8', 'pass_9', 'pass_10', 'pass_11', 'pass_12', 'pass_13', 'pass_14']\n"
     ]
    }
   ],
   "source": [
    "# Define all_trip_names and pass_lists\n",
    "def natural_key(string):\n",
    "    \"\"\"A key to sort strings that contain numbers naturally.\"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', string)]\n",
    "\n",
    "all_trip_names = ['16006', '16008', '16009', '16010', '16011']\n",
    "# Initialize the dictionary with empty sets for each trip\n",
    "pass_names_for_each_trip = {trip: set() for trip in all_trip_names}\n",
    "\n",
    "# Populate the sets with pass names from the segments\n",
    "for segment in segments.values():\n",
    "    trip_name = segment.attrs[\"trip_name\"]\n",
    "    pass_name = segment.attrs[\"pass_name\"]\n",
    "    pass_names_for_each_trip[trip_name].add(pass_name)\n",
    "\n",
    "# Convert sets to sorted lists using the natural key for sorting\n",
    "for trip in pass_names_for_each_trip:\n",
    "    pass_names_for_each_trip[trip] = sorted(pass_names_for_each_trip[trip], key=natural_key)\n",
    "\n",
    "# Variable assignments for pass lists\n",
    "for trip, passes in pass_names_for_each_trip.items():\n",
    "    globals()[f'pass_list_{trip}'] = passes\n",
    "\n",
    "# Displaying the sorted lists (this would typically be for debugging or checking, not part of production code)\n",
    "pass_lists = {trip: sorted(passes, key=natural_key) for trip, passes in pass_names_for_each_trip.items()}\n",
    "for trip in pass_lists:\n",
    "    print(f\"{trip}: {pass_lists[trip]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16006': {'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_15': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_16': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_17': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_18': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_19': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}, '16008': {'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_15': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_16': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_17': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}, '16009': {'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}, '16010': {'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}, '16011': {'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}}\n",
      "{'pass_1': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_2': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_3': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_4': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_5': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_6': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_7': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_8': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_9': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_10': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_11': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_12': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_13': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}, 'pass_14': {'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}}\n",
      "{'distance_segment_second_1': [100, 0, 0], 'distance_segment_second_2': [200, 0, 0]}\n",
      "[100, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the mapping dictionary\n",
    "mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip = {}\n",
    "\n",
    "for index in range(len(loc_vh)):\n",
    "    trip_data = {}\n",
    "    for trip_name in all_trip_names:\n",
    "        pass_data = {}\n",
    "        for pass_name in pass_lists[trip_name]:\n",
    "            pass_data[pass_name] = {\n",
    "                \"distance_segment_second_1\": [100, 0, 0],\n",
    "                \"distance_segment_second_2\": [200, 0, 0]\n",
    "            }\n",
    "        trip_data[trip_name] = pass_data\n",
    "    mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip[index] = trip_data\n",
    "\n",
    "# Accessing the structure for the first index\n",
    "print(mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip[0])\n",
    "print(mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip[0]['16011'])\n",
    "print(mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip[0]['16011']['pass_1'])\n",
    "print(mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip[0]['16011']['pass_1']['distance_segment_second_1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 940/940 [38:49<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Now fill out the dictionary with the correct values\n",
    "for index, real_location in tqdm(enumerate(loc_vh), total=len(loc_vh), desc=\"Processing\"):\n",
    "    for segment in segments.keys():\n",
    "        current_direction = segments[str(segment)].attrs[\"direction\"]\n",
    "        if current_direction == \"hh\": # Check that we are going in the right direction\n",
    "            continue\n",
    "        current_trip_name = segments[str(segment)].attrs[\"trip_name\"]\n",
    "        current_pass_name = segments[str(segment)].attrs[\"pass_name\"]\n",
    "        current_best_trip_1 = mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name][current_pass_name]['distance_segment_second_1']\n",
    "        current_best_trip_2 = mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name][current_pass_name]['distance_segment_second_2']\n",
    "        for second in segments[str(segment)].keys():\n",
    "            current_second = segments[str(segment)][str(second)]\n",
    "            current_second_lat = current_second[\"gm\"][:,15]\n",
    "            current_second_lon = current_second[\"gm\"][:,16]\n",
    "            current_second_locations = [[lon, lat] for lon, lat in zip(current_second_lon, current_second_lat)]\n",
    "            closest_sample_arg = np.argmin(np.linalg.norm(np.column_stack((current_second_lon, current_second_lat)) - np.array([real_location[0], real_location[1]]), axis=1))\n",
    "            best_at_second = current_second_locations[closest_sample_arg]\n",
    "            distance = np.linalg.norm(np.array(best_at_second) - np.array(real_location))\n",
    "            \n",
    "            if distance < current_best_trip_1[0]:\n",
    "                current_best_trip_2 = current_best_trip_1\n",
    "                current_best_trip_1 = [distance, segment, second]\n",
    "                mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name][current_pass_name]['distance_segment_second_1'] = current_best_trip_1\n",
    "                mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name][current_pass_name]['distance_segment_second_2'] = current_best_trip_2\n",
    "                \n",
    "            elif distance < current_best_trip_2[0]:\n",
    "                current_best_trip_2 = [distance, segment, second]\n",
    "                mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip[index][current_trip_name][current_pass_name]['distance_segment_second_2'] = current_best_trip_2\n",
    "            \n",
    "            else: \n",
    "                continue\n",
    "\n",
    "# Save the VH mapping to a CSV file\n",
    "filename = \"mapping_vh_time_to_location.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow(['Index', 'Trip Name', 'Pass Name', 'Distance Segment', 'Value1', 'Value2', 'Value3'])\n",
    "    # Write the data\n",
    "    for index, trips in mapping_vh_to_the_two_best_seconds_for_each_pass_in_each_trip.items():\n",
    "        for trip_name, passes in trips.items():\n",
    "            for pass_name, segments in passes.items():\n",
    "                for segment_name, values in segments.items():\n",
    "                    # Prepare the row with all needed information\n",
    "                    row = [index, trip_name, pass_name, segment_name] + values\n",
    "                    writer.writerow(row)\n",
    "\n",
    "print(\"CSV file has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After mapping each AOI to 2 time windows for each car, we will predict the KPI of the AOI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are in total 1226 AOIs for HH and 940 for VH.\n",
    "\n",
    "We have 10 windows for each AOI; 2 for each car and we have 5 cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the speed to estimate the amount of sample points there are in the area of interest (AOI)\n",
    "# The AOI is thought to be defined by an X meter long segment\n",
    "A_speed = 50\n",
    "B_speed = 30\n",
    "C_speed = 40\n",
    "\n",
    "sample_freq = 250  # Sample frequency in Hz\n",
    "A_samples = time_to_drive_X_meters(A_speed) * sample_freq\n",
    "B_samples = time_to_drive_X_meters(B_speed) * sample_freq\n",
    "C_samples = time_to_drive_X_meters(C_speed) * sample_freq\n",
    "total_samples = A_samples + B_samples + C_samples\n",
    "\n",
    "A_weight = A_samples / total_samples\n",
    "B_weight = B_samples / total_samples\n",
    "C_weight = C_samples / total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now localise the point of interest in the time domains.\n",
    "# It does not work to just take the first and last lon. and lat. and not the median either. \n",
    "# We need to be able to find the location fast, right now we will just \n",
    "\n",
    "# Should they all have a dictionary?\n",
    "A_t1_data = [[1,2,3,4,5,6,7,8,9,10],\n",
    "        [1,2,3,4,5,6,7,8,9,10],\n",
    "        [1,2,3,4,5,6,7,8,9,10],\n",
    "        [1,2,3,4,5,6,7,8,9,10],\n",
    "        [1,2,3,4,5,6,7,8,9,10],\n",
    "        [1,2,3,4,5,6,7,8,9,10]]\n",
    "A_t1_pred = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more yes\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "\n",
    "if x > 13:\n",
    "    print(\"yes\")\n",
    "    \n",
    "elif x > 1.5:\n",
    "    print(\"more yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance: 50\n",
      "current_best_trip_1: [50, 1, 1]\n",
      "current_best_trip_2: [50, 1, 1]\n",
      "best_1: [50, 1, 1]\n",
      "best_2: [50, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# TODO There is a bug where current_best_trip_1 == current_best_trip_2 sometimes\n",
    "current_best_trip_1 = [100, 0, 0]\n",
    "current_best_trip_2 = [200, 0, 0]\n",
    "\n",
    "distance, segment, second = 50, 1, 1\n",
    "\n",
    "best_1 = 1\n",
    "best_2 = 2\n",
    "\n",
    "if distance < current_best_trip_1[0]:\n",
    "    current_best_trip_2 = current_best_trip_1\n",
    "    current_best_trip_1 = [distance, segment, second]\n",
    "    best_1 = current_best_trip_1\n",
    "    best_2 = current_best_trip_2\n",
    "    \n",
    "elif distance < current_best_trip_2[0]:\n",
    "    current_best_trip_2 = [distance, segment, second]\n",
    "    best_2 = current_best_trip_2\n",
    "\n",
    "if distance < current_best_trip_1[0]:\n",
    "    current_best_trip_2 = current_best_trip_1\n",
    "    current_best_trip_1 = [distance, segment, second]\n",
    "    best_1 = current_best_trip_1\n",
    "    best_2 = current_best_trip_2\n",
    "    \n",
    "elif distance < current_best_trip_2[0]:\n",
    "    current_best_trip_2 = [distance, segment, second]\n",
    "    best_2 = current_best_trip_2\n",
    "\n",
    "print(f\"distance: {distance}\")\n",
    "print(f\"current_best_trip_1: {current_best_trip_1}\")\n",
    "print(f\"current_best_trip_2: {current_best_trip_2}\")\n",
    "print(f\"best_1: {best_1}\")\n",
    "print(f\"best_2: {best_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
